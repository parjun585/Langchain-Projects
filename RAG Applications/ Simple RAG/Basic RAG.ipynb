{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b544f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.llms import HuggingFaceHub  # or use OpenAI, Ollama, etc.\n",
    "\n",
    "# Step 1: Load a Wikipedia Page\n",
    "loader = WikipediaLoader(query=\"Natural Language Processing\", lang=\"en\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Step 2: Split into Chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "docs_chunked = splitter.split_documents(docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd7f03cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Embed and Store in FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(docs_chunked, embedding_model)\n",
    "\n",
    "# Step 4: Create Retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8543274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define Prompt Template\n",
    "template = \"\"\"\n",
    "Use the following context to answer the question.\n",
    "If you don't know the answer, just say you don't know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "343c940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Choose Your LLM\n",
    "# llm = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\": 0.3, \"max_length\": 512})\n",
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "# Step 7: Chain Components Together\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9eeaa97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  RAG Answer: NLP stands for Natural Language Processing. \n",
      "\n",
      "According to the provided text, it is:\n",
      "\n",
      "\"the processing of natural language information by a computer. The study of NLP, a subfield of computer science, is generally associated with artificial intelligence. NLP is related to information retrieval, knowledge representation, computational linguistics, and more broadly with linguistics.\" \n",
      "\n",
      "\n",
      "It involves tasks like speech recognition, text classification, natural language understanding, and natural language generation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Invoke RAG\n",
    "question = \"What is NLP?\"\n",
    "response = rag_chain.invoke(question)\n",
    "print(\"ðŸ§  RAG Answer:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9418a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 alternative, by importing a prompt from the langchain prompt hub \n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f21d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Choose Your LLM\n",
    "# llm = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\": 0.3, \"max_length\": 512})\n",
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "# Step 7: Chain Components Together\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough(),  # keeps user input untouched\n",
    "    }\n",
    "    | prompt  # this comes from hub.pull(...)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31ecc280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  RAG Answer: NLP stands for Natural Language Processing. \n",
      "It is a field of computer science that focuses on enabling computers to understand, interpret, and generate human language. \n",
      "NLP encompasses various tasks like speech recognition, text classification, and machine translation.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Invoke RAG\n",
    "question = \"What is NLP?\"\n",
    "response = rag_chain.invoke(question)\n",
    "print(\"ðŸ§  RAG Answer:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cbf1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
